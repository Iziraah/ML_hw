{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваша задача — реализовать алгоритм случайного леса для задачи классификации и применить его к набору данных. \n",
    "\n",
    "Шаги выполнения задания:\n",
    "\n",
    "Импортируйте необходимые библиотеки: numpy, pandas, sklearn.\n",
    "\n",
    "Загрузите набор данных для задачи классификации. Вы можете использовать любой доступный набор данных или выбрать один из популярных, таких как Iris, Wine или MNIST.\n",
    "\n",
    "Проведите предварительную обработку данных, включая масштабирование и разделение на обучающую и тестовую выборки.\n",
    "\n",
    "Реализуйте алгоритм случайного леса. Включите в него функции для построения деревьев решений, выбора случайных признаков и голосования для принятия решений.\n",
    "\n",
    "Обучите вашу модель случайного леса на обучающей выборке.\n",
    "\n",
    "Оцените производительность модели на тестовой выборке, используя метрики классификации, такие как точность, полнота и F1-мера.\n",
    "\n",
    "Проведите сравнение результатов вашей модели со стандартной реализацией случайного леса из библиотеки scikit-learn.\n",
    "\n",
    "## РЕШЕНИЕ \n",
    "Импортируем необходимые библиотеки для работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Загружаем набор данных Iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предварительная обработка данных\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Масштабирование данных\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Реализация алгоритма случайного леса\n",
    "\n",
    "Теперь создадим класс для случайного леса, который будет включать создание деревьев и процедуру голосования.\n",
    "\n",
    "#### Обучение модели случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y)\n",
    "\n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        num_samples, num_features = X.shape\n",
    "        unique_classes = np.unique(y)\n",
    "        \n",
    "        # Если все классы одинаковые, возвращаем их\n",
    "        if len(unique_classes) == 1:\n",
    "            return unique_classes[0]\n",
    "        \n",
    "        # Если достигли максимальной глубины, возвращаем моду\n",
    "        if self.max_depth is not None and depth >= self.max_depth:\n",
    "            return self._majority_class(y)\n",
    "\n",
    "        # Поиск наилучшего разбиения\n",
    "        best_gain = -1\n",
    "        best_split = None\n",
    "        best_left_indices = None\n",
    "        best_right_indices = None\n",
    "\n",
    "        for feature_index in range(num_features):  # Перебор всех признаков\n",
    "            thresholds = np.unique(X[:, feature_index])\n",
    "            for threshold in thresholds:  # Перебор всех возможных значений разбиения\n",
    "                left_indices = np.where(X[:, feature_index] <= threshold)[0]\n",
    "                right_indices = np.where(X[:, feature_index] > threshold)[0]\n",
    "\n",
    "                if len(left_indices) > 0 and len(right_indices) > 0:\n",
    "                    gain = self._information_gain(y, left_indices, right_indices)\n",
    "\n",
    "                    if gain > best_gain:\n",
    "                        best_gain = gain\n",
    "                        best_split = (feature_index, threshold)\n",
    "                        best_left_indices = left_indices\n",
    "                        best_right_indices = right_indices\n",
    "\n",
    "        if best_gain == -1:\n",
    "            return self._majority_class(y)\n",
    "\n",
    "        # Рекурсивное построение поддеревьев\n",
    "        left_tree = self._build_tree(X[best_left_indices], y[best_left_indices], depth + 1)\n",
    "        right_tree = self._build_tree(X[best_right_indices], y[best_right_indices], depth + 1)\n",
    "\n",
    "        return (best_split, left_tree, right_tree)\n",
    "\n",
    "    def _information_gain(self, y, left_indices, right_indices):\n",
    "        p = float(len(left_indices)) / len(y)\n",
    "        return self._gini(y) - p * self._gini(y[left_indices]) - (1 - p) * self._gini(y[right_indices])\n",
    "\n",
    "    def _gini(self, y):\n",
    "        classes, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / len(y)\n",
    "        return 1 - np.sum(probabilities ** 2)\n",
    "\n",
    "    def _majority_class(self, y):\n",
    "        return np.bincount(y).argmax()\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = [self._predict_sample(sample, self.tree) for sample in X]\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict_sample(self, sample, tree):\n",
    "        if isinstance(tree, tuple):  # Если это узел дерева\n",
    "            feature_index, threshold = tree[0]\n",
    "            if sample[feature_index] <= threshold:\n",
    "                return self._predict_sample(sample, tree[1])\n",
    "            else:\n",
    "                return self._predict_sample(sample, tree[2])\n",
    "        else:\n",
    "            return tree  # Если это лист дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_trees=100, max_depth=None):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for _ in range(self.n_trees):\n",
    "            # Бутстрэппинг: выбираем случайные подмножества данных\n",
    "            indices = np.random.choice(len(X), len(X), replace=True)\n",
    "            X_subsample, y_subsample = X[indices], y[indices]\n",
    "            tree = DecisionTree(max_depth=self.max_depth)\n",
    "            tree.fit(X_subsample, y_subsample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Получение предсказаний от каждого дерева\n",
    "        predictions = np.array([tree.predict(X) for tree in self.trees])\n",
    "        # Голосование\n",
    "        return np.array([np.bincount(p).argmax() for p in predictions.T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение модели случайного леса\n",
    "model = RandomForest(n_trees=100, max_depth=5)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка производительности модели\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 1.0000\n",
      "Точность: 1.0000\n",
      "Полнота: 1.0000\n",
      "F1-мера: 1.0000\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f'Точность: {accuracy:.4f}')\n",
    "print(f'Точность: {precision:.4f}')\n",
    "print(f'Полнота: {recall:.4f}')\n",
    "print(f'F1-мера: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объяснение:\n",
    "#### Класс DecisionTree:\n",
    "- Метод fit обучает дерево, создавая рекурсивно его структуру, выбирая наилучшее разбиение по критерию Джини.\n",
    "- Метод _build_tree строит дерево.\n",
    "- Метод _predict_sample предсказывает класс для отдельного наблюдения.\n",
    "\n",
    "#### Класс RandomForest:\n",
    "- Метод fit создает несколько деревьев, обучая каждое из них на бутстрэппированной выборке.\n",
    "- Метод predict собирает предсказания всех деревьев и использует голосование для определения итогового класса.\n",
    "\n",
    "#### Обучение и оценка:\n",
    "- Набор данных Iris загружается, разбивается на обучающую и тестовую выборки.\n",
    "- Модель случайного леса обучается и оценивается с использованием метрик точности, точности, полноты и F1-меры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение сo стандартной реализацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sklearn = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model_sklearn.fit(X_train, y_train)\n",
    "y_pred_sklearn = model_sklearn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность (sklearn): 1.0000\n",
      "Точность (sklearn): 1.0000\n",
      "Полнота (sklearn): 1.0000\n",
      "F1-мера (sklearn): 1.0000\n"
     ]
    }
   ],
   "source": [
    "accuracy_sklearn = accuracy_score(y_test, y_pred_sklearn)\n",
    "precision_sklearn = precision_score(y_test, y_pred_sklearn, average='macro')\n",
    "recall_sklearn = recall_score(y_test, y_pred_sklearn, average='macro')\n",
    "f1_sklearn = f1_score(y_test, y_pred_sklearn, average='macro')\n",
    "\n",
    "print(f'Точность (sklearn): {accuracy_sklearn:.4f}')\n",
    "print(f'Точность (sklearn): {precision_sklearn:.4f}')\n",
    "print(f'Полнота (sklearn): {recall_sklearn:.4f}')\n",
    "print(f'F1-мера (sklearn): {f1_sklearn:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты в обоих случаях оказались одинаковыми, что можно объяснить небольшим количеством признаков в датасете и их высокой корреляцией. Для практических целей удобнее и быстрее использовать стандартную реализацию.\n",
    "\n",
    "Метрики модели демонстрируют отличную производительность.\n",
    "\n",
    "- Точность (Precision) 1.0000 показывает, что модель правильно классифицирует все предсказанные положительные случаи.\n",
    "- Полнота (Recall) 1.0000 указывает на то, что модель выявляет все истинные положительные случаи. \n",
    "- F1-мера 1.0000 — это гармоническое среднее точности и полноты, подтверждающее идеальную сбалансированную производительность модели.\n",
    "\n",
    "Такой идеальный результат редко встречается в реальных задачах. Важно помнить, что это может быть обусловлено следующими факторами:\n",
    "\n",
    "- Недостатком данных: модель может быть обучена на слишком простом наборе данных, где классы легко различимы.\n",
    "- Переобучением: модель может переобучиться на тренировочных данных и плохо обобщать на новые данные."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
